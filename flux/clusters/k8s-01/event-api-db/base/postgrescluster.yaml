apiVersion: postgres-operator.crunchydata.com/v1beta1
kind: PostgresCluster
metadata:
  name: db-event-api
  labels:
    app.kubernetes.io/component: database
    app.kubernetes.io/managed-by: flux
    app.kubernetes.io/name: db-event-api
    app.kubernetes.io/part-of: event-api
spec:
  backups:
    pgbackrest:
      repos:
        - name: repo1
          volume:
            volumeClaimSpec:
              accessModes:
                - ReadWriteOnce
              resources:
                requests:
                  storage: 100Gi
              storageClassName: local-path-regular
  instances:
    - affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - weight: 1
              podAffinityTerm:
                topologyKey: kubernetes.io/hostname
                labelSelector:
                  matchLabels:
                    postgres-operator.crunchydata.com/cluster: db-event-api
                    postgres-operator.crunchydata.com/instance-set: '01'
      dataVolumeClaimSpec:
        accessModes:
          - ReadWriteOnce
        resources:
          requests:
            storage: 100Gi
      name: '01'
      replicas: 1
      resources:
        limits:
          memory: 512Gi # # let Postres use the page cache
          cpu: '64' # set as event-api pool size + autovacuum workers + a bit for parallel workers
        requests:
          memory: 22Gi # roughly shared_buffers + pool size * work_mem
          cpu: '2' # if we don't have CPU we can run on potato
      topologySpreadConstraints:
        - maxSkew: 1
          topologyKey: kubernetes.io/hostname
          whenUnsatisfiable: DoNotSchedule
          labelSelector:
            matchLabels:
              postgres-operator.crunchydata.com/instance-set: '01'
  metadata:
    labels:
      app.kubernetes.io/component: database
      app.kubernetes.io/managed-by: pgo
      app.kubernetes.io/name: db-event-api
      app.kubernetes.io/part-of: event-api
  patroni:
    dynamicConfiguration:
      postgresql:
        parameters:
          auto_explain.log_min_duration: 1s
          auto_explain.log_nested_statements: 'on'
          auto_explain.log_verbose: 'on'
          autovacuum_analyze_scale_factor: 0.005
          autovacuum_naptime: 15s
          autovacuum_vacuum_cost_limit: -1 # we want vacuum to happen at full speed
          autovacuum_vacuum_insert_scale_factor: 0.01
          autovacuum_vacuum_scale_factor: 0.01
          effective_cache_size: 60GB # should be close to memory limit
          effective_io_concurrency: 200
          log_autovacuum_min_duration: 250ms
          log_checkpoints: 'on'
          log_error_verbosity: verbose
          log_line_prefix: '[%m u=%u d=%d h=%r p=%p l=%l trans_id=%x]: '
          maintenance_work_mem: 2GB
          max_connections: 100 # don't lower max_connections below 100 - unused don't consume anything but you may be able to connect one day
          max_parallel_maintenance_workers: 4
          max_parallel_workers: 16
          max_parallel_workers_per_gather: 4
          max_worker_processes: 16
          random_page_cost: 1.1
          shared_buffers: 6GB
          shared_preload_libraries: 'auto_explain,pg_stat_statements'
          track_activity_query_size: 4kB
          track_functions: pl
          track_io_timing: 'on'
          vacuum_cost_page_miss: 2 # default value
          wal_compression: 'on'
          work_mem: 1GB
          wal_level: replica
  postGISVersion: '3.2'
  postgresVersion: 14
  users:
    - name: postgres
    - name: event-api
      databases:
        - event-api
      options: SUPERUSER
